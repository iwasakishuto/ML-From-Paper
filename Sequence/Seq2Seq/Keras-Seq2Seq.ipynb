{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets: [Tab-delimited Bilingual Sentence Pairs ](http://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"./data/fra.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(file_name, names=[\"en\", \"fra\"], encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     en      fra\n",
       "0   Go.     Va !\n",
       "1   Hi.  Salut !\n",
       "2  Run!  Cours !"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "we make a dictionary of the words used in the text we want to process (or sometimes we use the most frequent 10,000 words of the text’s language.)<br>\n",
    "To make it easy to understand what we are going to do, we will :\n",
    "1. Convert text to <b>lowercase</b>\n",
    "2. Clean data from <b>digits and punctuation</b>\n",
    "3. Append <b>\"SOS\" (_Start of Sentence_)</b> and <b>\"EOS\" (_End of Sentence_)</b> to the target data\n",
    "4. Make dictionaries to <b>convert words to indexed numbers</b>\n",
    "5. Use <b>embedding layer</b> to convert each word to a fixed length vector.<b>(Word embeddings provide a dense representation of words and their relative meanings)</b>\n",
    "6. Now, <b>the data is ready to be used by seq2seq network.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.en  = df.en.apply(lambda x:x.lower())\n",
    "df.fra = df.fra.apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean data from digits and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me, too.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[182].en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.en  = df.en.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "df.fra = df.fra.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me COMMA too.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[182].en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3].en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "df.en  = df.en.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df.fra = df.fra.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3].en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im 19'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[51].en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "df.en  = df.en.apply(lambda x: x.translate(remove_digits))\n",
    "df.fra = df.fra.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[51].en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Append \"SOS\" _(Start of Sentence)_ and \"EOS\" _(End of Sentence)_ to the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'va '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fra.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending SOS andEOS to target data :\n",
    "df.fra = df.fra.apply(lambda x : 'SOS_ '+ x + ' _EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS_ va  _EOS'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fra.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make dictionaries to convert words to indexed numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words=set()\n",
    "for line in df.en:\n",
    "    for word in line.split(\" \"):\n",
    "        if word not in en_words:\n",
    "            en_words.add(word)\n",
    "    \n",
    "fra_words=set()\n",
    "for line in df.fra:\n",
    "    for word in line.split(\" \"):\n",
    "        if word not in fra_words:\n",
    "            fra_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_en_words:  14251\n",
      "num_fra_words: 32357\n"
     ]
    }
   ],
   "source": [
    "num_en_words  = len(en_words)\n",
    "num_fra_words = len(fra_words)\n",
    "print(\"num_en_words:  {}\".format(num_en_words))\n",
    "print(\"num_fra_words: {}\".format(num_fra_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_en_words_per_sample:  54\n",
      "max_fra_words_per_sample: 63\n"
     ]
    }
   ],
   "source": [
    "max_en_words_per_sample  = max([len(sample.split(\" \")) for sample in df.en])+5\n",
    "max_fra_words_per_sample = max([len(sample.split(\" \")) for sample in df.fra])+5\n",
    "print(\"max_en_words_per_sample:  {}\".format(max_en_words_per_sample))\n",
    "print(\"max_fra_words_per_sample: {}\".format(max_fra_words_per_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_en_samples:  167130\n",
      "num_fra_samples: 167130\n"
     ]
    }
   ],
   "source": [
    "num_en_samples = len(df.en)\n",
    "num_fra_samples = len(df.fra)\n",
    "print(\"num_en_samples:  {}\".format(num_en_samples))\n",
    "print(\"num_fra_samples: {}\".format(num_fra_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en words sample:  ['', 'locusts', 'certain']\n",
      "fra words sample: ['', 'durèrent', 'présent\\xa0']\n"
     ]
    }
   ],
   "source": [
    "print(\"en words sample:  {}\".format(list(en_words)[:3]))\n",
    "print(\"fra words sample: {}\".format(list(fra_words)[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_words = sorted(list(en_words))\n",
    "target_words = sorted(list(fra_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en words sample:  ['', 'COMMA', 'COMMA\\xa0ill']\n",
      "fra words sample: ['', 'COMMA', 'COMMAenfila']\n"
     ]
    }
   ],
   "source": [
    "print(\"en words sample:  {}\".format(input_words[:3]))\n",
    "print(\"fra words sample: {}\".format(target_words[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizing the words (Convert to numbers)\n",
    "en_token_to_int = dict()\n",
    "en_int_to_token = dict()\n",
    "\n",
    "for i,token in enumerate(input_words):\n",
    "    en_token_to_int[token] = i\n",
    "    en_int_to_token[i]     = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_int_to_token[en_token_to_int[\"COMMA\"]] == \"COMMA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fra_token_to_int = dict()\n",
    "fra_int_to_token = dict()\n",
    "for i,token in enumerate(target_words):\n",
    "    fra_token_to_int[token] = i\n",
    "    fra_int_to_token[i]     = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_int_to_token[fra_token_to_int[\"COMMA\"]] == \"COMMA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate numpy arrays to hold the data that our seq2seq model will use:\n",
    "encoder_input_data  = np.zeros((num_en_samples,  max_en_words_per_sample),  dtype='float32')\n",
    "decoder_input_data  = np.zeros((num_fra_samples, max_fra_words_per_sample), dtype='float32')\n",
    "decoder_target_data = np.zeros((num_fra_samples, max_fra_words_per_sample, num_fra_words), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_data shape:  (167130, 54)\n",
      "decoder_input_data shape:  (167130, 63)\n",
      "decoder_target_data shape: (167130, 63, 32357)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input_data shape:  {}\".format(encoder_input_data.shape))\n",
    "print(\"decoder_input_data shape:  {}\".format(decoder_input_data.shape))\n",
    "print(\"decoder_target_data shape: {}\".format(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(df.en, df.fra)):\n",
    "    \"\"\"\n",
    "    ex.)\n",
    "    input_text ：Go\n",
    "    target_text：SOS_ Va  _EOS\n",
    "    \"\"\"\n",
    "    for t, word in enumerate(input_text.split(\" \")):\n",
    "        \"\"\" ex.) word：Go \"\"\"\n",
    "        encoder_input_data[i, t] = en_token_to_int[word]\n",
    "    for t, word in enumerate(target_text.split(\" \")):\n",
    "        \"\"\" ex.) word：SOS_ \"\"\"\n",
    "        decoder_input_data[i, t] = fra_token_to_int[word]\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, fra_token_to_int[word]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5420.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.0000e+00, 3.0359e+04, 0.0000e+00, 7.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use embedding layer to convert each word to a fixed length vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining some constants: \n",
    "vec_len       = 300   # Length of the vector that we willl get from the embedding layer\n",
    "latent_dim    = 1024  # Hidden layers dimension \n",
    "dropout_rate  = 0.2   # Rate of the dropout layers\n",
    "batch_size    = 64    # Batch size\n",
    "epochs        = 30    # Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the encoder.\n",
    "\n",
    "|Layer name|Brief content|\n",
    "|:--|:--|\n",
    "|Input Layer|Takes the English sentence and pass it to the embedding layer.|\n",
    "|Embedding Layer|  Takes the English sentence and convert each word to fixed size vector.|\n",
    "|First LSTM Layer|  Every time step, it takes a vector that represents a word and pass its output to the next layer, We used CuDNNLSTM layer instead of LSTM because it’s much much faster.|\n",
    "|Second LSTM Layer|  It does the same thing as the previous layer, but instead of passing its output, it passes its states to the first LSTM layer of the decoder.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>figure is below;\n",
    "    <details><img src=\"https://cdn-images-1.medium.com/max/1600/1*3pH2NH_8i7QMxpV0TFOdxw.jpeg\"></details>\n",
    "</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/iwasakishuto/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/iwasakishuto/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Input layer:\n",
    "encoder_input = keras.layers.Input(shape=(None,))\n",
    "\n",
    "# Hidden layers\n",
    "encoder_embedding = keras.layers.Embedding(input_dim=num_en_words, output_dim=vec_len)(encoder_input) \n",
    "encoder_dropout   = (keras.layers.TimeDistributed(keras.layers.Dropout(rate=dropout_rate)))(encoder_embedding)\n",
    "encoder_LSTM      = keras.layers.LSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
    "\n",
    "# Output layer:\n",
    "encoder_LSTM2_layer = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM2_layer(encoder_LSTM)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the decoder.\n",
    "\n",
    "|Layer name|Brief content|\n",
    "|:--|:--|\n",
    "|Input Layer | Takes the French sentence and pass it to the embedding layer.|\n",
    "|Embedding Layer | Takes the French sentence and convert each word to fixed size vector|\n",
    "|First LSTM Layer | Every time step, it takes a vector that represents a word and pass its output to the next layer, but here in the decoder, we initialize the state of this layer to be the last state of the last LSTM layer from the decoder .|\n",
    "|Second LSTM Layer | Processing the output from the previous layer and passes its output to a dense layer .|\n",
    "|Dense Layer (Output Layer) | Takes the output from the previous layer and outputs a one hot vector representing the target French word|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>figure is below;\n",
    "    <details><img src=\"https://cdn-images-1.medium.com/max/1600/1*sDlV9_-PXBlt8jol-7Xjhg.jpeg\"></details>\n",
    "</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer:\n",
    "decoder_input = keras.layers.Input(shape=(None,))\n",
    "\n",
    "# Hidden layers:\n",
    "decoder_embedding_layer = keras.layers.Embedding(input_dim=num_fra_words, output_dim=vec_len)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "decoder_dropout_layer = (keras.layers.TimeDistributed(keras.layers.Dropout(rate = dropout_rate)))\n",
    "decoder_dropout = decoder_dropout_layer(decoder_embedding)\n",
    "\n",
    "decoder_LSTM_layer = keras.layers.LSTM(latent_dim, return_sequences=True)\n",
    "decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state=encoder_states)\n",
    "\n",
    "decoder_LSTM_2_layer = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_LSTM_2,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\n",
    "\n",
    "# Output layer:\n",
    "decoder_dense = keras.layers.Dense(num_fra_words, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_LSTM_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;border-radius: 10px; border: 5px double #FA8072;\">\n",
    "<b>Note :</b><br>\n",
    "We have to know that we don’t convert each English sentence into French in one time step, we do that in a number of time steps that equals the number of words that the longest English sentence has.<br>\n",
    "so if the longest English sentence has 10 words, we have to take 10 time steps to get its French translation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing the encoder and decoder together into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    4275300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    9707100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 1024)   5427200     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 300)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1024), (None 8392704     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, None, 1024)   5427200     time_distributed_2[0][0]         \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 1024), 8392704     lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 32357)  33165925    lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 74,788,133\n",
      "Trainable params: 74,788,133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file=\"./img/model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>figure is below;\n",
    "    <details><img src=\"./img/model.png\"></details>\n",
    "</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a checkpoint callback :\n",
    "checkpoint_name = './weights/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train_samples = 9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data[:num_train_samples,:],\n",
    "               decoder_input_data[:num_train_samples,:]],\n",
    "               decoder_target_data[:num_train_samples,:,:],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.08,\n",
    "          callbacks = callbacks_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
